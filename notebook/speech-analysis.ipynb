{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract info from audio files\n",
    "def extract_audio_features(file_name, mfcc, chroma, mel):\n",
    "    \"\"\"\n",
    "    mfcc represents the short term power spectrum of the sound\n",
    "    chroma is the pitch\n",
    "    mel is the spectrogram frequency\n",
    "    \"\"\"\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate = sound_file.samplerate\n",
    "        if chroma:\n",
    "            fourier = np.abs(librosa.stft(X))\n",
    "            \n",
    "        # compile the three features into a result    \n",
    "        result = np.array([])\n",
    "\n",
    "        if mfcc:\n",
    "            pwr_spec = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, pwr_spec)) # add to result\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=fourier, \n",
    "                                                        sr=sample_rate,\n",
    "                                                        ).T, axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the emotion labels in the RAVDESS dataset\n",
    "emotions = {\n",
    "    '01': 'neutral',\n",
    "    '02': 'calm',    \n",
    "    '03': 'happy',\n",
    "    '04': 'sad',\n",
    "    '05': 'angry',\n",
    "    '06': 'fearful',\n",
    "    '07': 'disgust',    \n",
    "    '08': 'surprised' \n",
    "    }\n",
    "# we are looking at a subset of emotions of interest    \n",
    "observed_emotions = ('sad', 'happy', 'fearful', 'surprised' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files in. \n",
    "# We needed the previous functions to make sense of the filename and info\n",
    "\n",
    "def load_data(test_size=0.2):\n",
    "    x,y = [], []\n",
    "    # use the glob library to parse through files with wildcard\n",
    "    files = [file for file in glob.glob(\"..\\data\\Actor_*\\*.wav\")]\n",
    "    for file in files:\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion = emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature = extract_audio_features(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this is a rather conservative split given the amount of data.\n",
    "# First I will run it as is but then I want to train on more of the data \n",
    "# Could use data augmentation to beef it up.\n",
    "X_train, X_test, y_train, y_test = load_data(test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'> <class 'list'>\nshapes of data: ((614, 180), (154, 180), (154,)) (614,)\nThe first number represents how many files, the second is how many feautures extracted\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train), type(y_test))\n",
    "print('shapes of data:', (np.array(X_train).shape, np.array(X_test).shape, np.array(y_test).shape), np.shape(y_train))\n",
    "print('The first number represents how many files, the second is how many feautures extracted' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The method shows here is from sklearn's neural network... could potentially try our own later\n",
    "# Multi Layer Perceptron Classifier\n",
    "model = MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(500,), learning_rate='adaptive', max_iter=500, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 1, loss = 20.89579859\n",
      "Iteration 2, loss = 9.48402521\n",
      "Iteration 3, loss = 9.23242576\n",
      "Iteration 4, loss = 7.20703311\n",
      "Iteration 5, loss = 3.76408598\n",
      "Iteration 6, loss = 4.07899478\n",
      "Iteration 7, loss = 3.28271669\n",
      "Iteration 8, loss = 3.79703887\n",
      "Iteration 9, loss = 2.02600256\n",
      "Iteration 10, loss = 2.34710678\n",
      "Iteration 11, loss = 1.77742139\n",
      "Iteration 12, loss = 1.43767627\n",
      "Iteration 13, loss = 1.59180284\n",
      "Iteration 14, loss = 1.33044353\n",
      "Iteration 15, loss = 1.23131094\n",
      "Iteration 16, loss = 1.17443287\n",
      "Iteration 17, loss = 1.11062840\n",
      "Iteration 18, loss = 1.05289812\n",
      "Iteration 19, loss = 1.03571937\n",
      "Iteration 20, loss = 1.04958473\n",
      "Iteration 21, loss = 0.98199835\n",
      "Iteration 22, loss = 1.06285670\n",
      "Iteration 23, loss = 1.11102844\n",
      "Iteration 24, loss = 0.97210655\n",
      "Iteration 25, loss = 1.03939402\n",
      "Iteration 26, loss = 0.94622273\n",
      "Iteration 27, loss = 0.93425317\n",
      "Iteration 28, loss = 0.82279339\n",
      "Iteration 29, loss = 0.79999273\n",
      "Iteration 30, loss = 0.75767514\n",
      "Iteration 31, loss = 0.74844225\n",
      "Iteration 32, loss = 0.74040972\n",
      "Iteration 33, loss = 0.73246367\n",
      "Iteration 34, loss = 0.70857492\n",
      "Iteration 35, loss = 0.75459945\n",
      "Iteration 36, loss = 0.74612565\n",
      "Iteration 37, loss = 0.71481041\n",
      "Iteration 38, loss = 0.72027329\n",
      "Iteration 39, loss = 0.68733185\n",
      "Iteration 40, loss = 0.71488343\n",
      "Iteration 41, loss = 0.71501225\n",
      "Iteration 42, loss = 0.69327466\n",
      "Iteration 43, loss = 0.68797373\n",
      "Iteration 44, loss = 0.64286864\n",
      "Iteration 45, loss = 0.64442990\n",
      "Iteration 46, loss = 0.60651786\n",
      "Iteration 47, loss = 0.58424558\n",
      "Iteration 48, loss = 0.58368891\n",
      "Iteration 49, loss = 0.62319131\n",
      "Iteration 50, loss = 0.62373679\n",
      "Iteration 51, loss = 0.62765169\n",
      "Iteration 52, loss = 0.56773698\n",
      "Iteration 53, loss = 0.56574075\n",
      "Iteration 54, loss = 0.59024369\n",
      "Iteration 55, loss = 0.58367505\n",
      "Iteration 56, loss = 0.57465069\n",
      "Iteration 57, loss = 0.55072706\n",
      "Iteration 58, loss = 0.57801178\n",
      "Iteration 59, loss = 0.56382303\n",
      "Iteration 60, loss = 0.52522923\n",
      "Iteration 61, loss = 0.53119633\n",
      "Iteration 62, loss = 0.53284490\n",
      "Iteration 63, loss = 0.49734223\n",
      "Iteration 64, loss = 0.49096590\n",
      "Iteration 65, loss = 0.49805164\n",
      "Iteration 66, loss = 0.49052495\n",
      "Iteration 67, loss = 0.47056732\n",
      "Iteration 68, loss = 0.46689236\n",
      "Iteration 69, loss = 0.46012098\n",
      "Iteration 70, loss = 0.46306998\n",
      "Iteration 71, loss = 0.46051826\n",
      "Iteration 72, loss = 0.46106465\n",
      "Iteration 73, loss = 0.46063235\n",
      "Iteration 74, loss = 0.45705697\n",
      "Iteration 75, loss = 0.42995744\n",
      "Iteration 76, loss = 0.45416521\n",
      "Iteration 77, loss = 0.47491075\n",
      "Iteration 78, loss = 0.41046520\n",
      "Iteration 79, loss = 0.44795006\n",
      "Iteration 80, loss = 0.40545847\n",
      "Iteration 81, loss = 0.41755820\n",
      "Iteration 82, loss = 0.41105979\n",
      "Iteration 83, loss = 0.44757355\n",
      "Iteration 84, loss = 0.50490321\n",
      "Iteration 85, loss = 0.51212982\n",
      "Iteration 86, loss = 0.48779287\n",
      "Iteration 87, loss = 0.46276892\n",
      "Iteration 88, loss = 0.43658899\n",
      "Iteration 89, loss = 0.38546133\n",
      "Iteration 90, loss = 0.40023390\n",
      "Iteration 91, loss = 0.39382121\n",
      "Iteration 92, loss = 0.37008698\n",
      "Iteration 93, loss = 0.36844417\n",
      "Iteration 94, loss = 0.38356173\n",
      "Iteration 95, loss = 0.38717902\n",
      "Iteration 96, loss = 0.41207120\n",
      "Iteration 97, loss = 0.41118408\n",
      "Iteration 98, loss = 0.38517762\n",
      "Iteration 99, loss = 0.38771828\n",
      "Iteration 100, loss = 0.35105945\n",
      "Iteration 101, loss = 0.35059132\n",
      "Iteration 102, loss = 0.35385815\n",
      "Iteration 103, loss = 0.39009900\n",
      "Iteration 104, loss = 0.35968334\n",
      "Iteration 105, loss = 0.35737069\n",
      "Iteration 106, loss = 0.35918152\n",
      "Iteration 107, loss = 0.39360989\n",
      "Iteration 108, loss = 0.35892888\n",
      "Iteration 109, loss = 0.35149135\n",
      "Iteration 110, loss = 0.32863541\n",
      "Iteration 111, loss = 0.30800695\n",
      "Iteration 112, loss = 0.34725734\n",
      "Iteration 113, loss = 0.33956168\n",
      "Iteration 114, loss = 0.33449792\n",
      "Iteration 115, loss = 0.33455089\n",
      "Iteration 116, loss = 0.29929741\n",
      "Iteration 117, loss = 0.29888881\n",
      "Iteration 118, loss = 0.32873687\n",
      "Iteration 119, loss = 0.31096835\n",
      "Iteration 120, loss = 0.28693615\n",
      "Iteration 121, loss = 0.28538331\n",
      "Iteration 122, loss = 0.31352367\n",
      "Iteration 123, loss = 0.28878743\n",
      "Iteration 124, loss = 0.29192903\n",
      "Iteration 125, loss = 0.29786235\n",
      "Iteration 126, loss = 0.30733089\n",
      "Iteration 127, loss = 0.28214074\n",
      "Iteration 128, loss = 0.28305557\n",
      "Iteration 129, loss = 0.28722310\n",
      "Iteration 130, loss = 0.26077389\n",
      "Iteration 131, loss = 0.25120921\n",
      "Iteration 132, loss = 0.27239744\n",
      "Iteration 133, loss = 0.26120773\n",
      "Iteration 134, loss = 0.26179147\n",
      "Iteration 135, loss = 0.27563690\n",
      "Iteration 136, loss = 0.28119797\n",
      "Iteration 137, loss = 0.26805919\n",
      "Iteration 138, loss = 0.28569458\n",
      "Iteration 139, loss = 0.29798151\n",
      "Iteration 140, loss = 0.30972857\n",
      "Iteration 141, loss = 0.27562630\n",
      "Iteration 142, loss = 0.24372942\n",
      "Iteration 143, loss = 0.24324873\n",
      "Iteration 144, loss = 0.22764461\n",
      "Iteration 145, loss = 0.22807422\n",
      "Iteration 146, loss = 0.22123760\n",
      "Iteration 147, loss = 0.21654968\n",
      "Iteration 148, loss = 0.21861776\n",
      "Iteration 149, loss = 0.21543863\n",
      "Iteration 150, loss = 0.24390409\n",
      "Iteration 151, loss = 0.21266968\n",
      "Iteration 152, loss = 0.20410153\n",
      "Iteration 153, loss = 0.21019644\n",
      "Iteration 154, loss = 0.23012679\n",
      "Iteration 155, loss = 0.22347151\n",
      "Iteration 156, loss = 0.22576078\n",
      "Iteration 157, loss = 0.23922380\n",
      "Iteration 158, loss = 0.24162977\n",
      "Iteration 159, loss = 0.22014957\n",
      "Iteration 160, loss = 0.20361124\n",
      "Iteration 161, loss = 0.18809071\n",
      "Iteration 162, loss = 0.18911946\n",
      "Iteration 163, loss = 0.20065583\n",
      "Iteration 164, loss = 0.18991281\n",
      "Iteration 165, loss = 0.18354366\n",
      "Iteration 166, loss = 0.17554614\n",
      "Iteration 167, loss = 0.18054574\n",
      "Iteration 168, loss = 0.17448107\n",
      "Iteration 169, loss = 0.19107949\n",
      "Iteration 170, loss = 0.18960652\n",
      "Iteration 171, loss = 0.20090592\n",
      "Iteration 172, loss = 0.18361486\n",
      "Iteration 173, loss = 0.19810542\n",
      "Iteration 174, loss = 0.18232950\n",
      "Iteration 175, loss = 0.18947923\n",
      "Iteration 176, loss = 0.18700972\n",
      "Iteration 177, loss = 0.19135612\n",
      "Iteration 178, loss = 0.19452273\n",
      "Iteration 179, loss = 0.21102403\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(500,),\n",
       "              learning_rate='adaptive', max_iter=500, verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.708\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy:', round(accuracy_score(y_true=y_test, y_pred=y_pred), ndigits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try reading in our own sample\n",
    "audio_sample = extract_audio_features('C:\\\\Users\\\\jonma\\\\Programming\\\\speech-emotion\\\\fearful-sample.wav', mfcc=True, chroma=True, mel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['fearful'], dtype='<U7')"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "model.predict(np.array(audio_sample).reshape(1, -1))\n",
    "# Hooray!!! It worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['fearful'], dtype='<U7')"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "audio_sample1 = extract_audio_features('C:\\\\Users\\\\jonma\\\\Programming\\\\speech-emotion\\\\disgust-sample.wav', mfcc=True, chroma=True, mel=True)\n",
    "model.predict(np.array(audio_sample1).reshape(1, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['fearful'], dtype='<U7')"
      ]
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "source": [
    "audio_sample2 = extract_audio_features('C:\\\\Users\\\\jonma\\\\Programming\\\\speech-emotion\\\\extra-disgust-sample.wav', mfcc=True, chroma=True, mel=True)\n",
    "model.predict(np.array(audio_sample2).reshape(1, -1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-emotion",
   "language": "python",
   "name": "speech-emotion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}